{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "gpu_options = tf.GPUOptions(visible_device_list=\"3\")\n",
    "config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True, device_count={'GPU': 1}, gpu_options=gpu_options)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f57641c88d0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f57641c89e8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f57e84303c8>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(5000, 784)\n",
      "(5000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(mnist.train.images))\n",
    "print(np.shape(mnist.train.labels))\n",
    "\n",
    "print(np.shape(mnist.validation.images))\n",
    "print(np.shape(mnist.validation.labels))\n",
    "\n",
    "print(np.shape(mnist.test.images))\n",
    "print(np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "total_batch = mnist.train.num_examples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니 배치 쓰는 이유\n",
    "# 1. gpu문제\n",
    "# 2. local optima 에 빠질 위험이 적다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784,256], stddev=0.01))\n",
    "B1 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L1 = tf.nn.sigmoid(tf.matmul(X,W1) + B1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,10], stddev=0.01))\n",
    "B2 = tf.Variable(tf.random_normal(shape=[10], stddev=0.01))\n",
    "model = tf.nn.softmax(tf.matmul(L1,W2)+B2)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(tf.clip_by_value(model, 1e-10, 1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Avg. cost = 0.606, Train Acc. = 0.8357636373896491\n",
      "Epoch: 0002, Avg. cost = 0.236, Train Acc. = 0.9319636395844546\n",
      "Epoch: 0003, Avg. cost = 0.185, Train Acc. = 0.9470545459877361\n",
      "Epoch: 0004, Avg. cost = 0.146, Train Acc. = 0.95752727616917\n",
      "Epoch: 0005, Avg. cost = 0.122, Train Acc. = 0.9645636412230405\n",
      "Epoch: 0006, Avg. cost = 0.104, Train Acc. = 0.9709090987118808\n",
      "Epoch: 0007, Avg. cost = 0.089, Train Acc. = 0.9750363729216835\n",
      "Epoch: 0008, Avg. cost = 0.076, Train Acc. = 0.9791454658725045\n",
      "Epoch: 0009, Avg. cost = 0.066, Train Acc. = 0.9814181928201156\n",
      "Epoch: 0010, Avg. cost = 0.056, Train Acc. = 0.9850000104037198\n",
      "Epoch: 0011, Avg. cost = 0.049, Train Acc. = 0.9867091008749875\n",
      "Epoch: 0012, Avg. cost = 0.041, Train Acc. = 0.9891454631632025\n",
      "Epoch: 0013, Avg. cost = 0.037, Train Acc. = 0.9901454624262723\n",
      "Epoch: 0014, Avg. cost = 0.031, Train Acc. = 0.9924181886152788\n",
      "Epoch: 0015, Avg. cost = 0.027, Train Acc. = 0.9942545509338379\n",
      "Training Done!\n",
      "Test Acc. =  0.9784\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        total_acc = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val, acc_val = sess.run([optimizer, cost, accuracy],\n",
    "                                           feed_dict={X:batch_xs, Y:batch_ys})\n",
    "            total_cost += cost_val\n",
    "            total_acc += acc_val\n",
    "            \n",
    "        print('Epoch: {0:04d}, Avg. cost = {1:.3f}, Train Acc. = {2}'.format(epoch + 1,\n",
    "                                                                             total_cost / total_batch,\n",
    "                                                                             total_acc / total_batch))\n",
    "    print('Training Done!')\n",
    "    print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------------------------\n",
    "# five layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784,1024], stddev=0.01))\n",
    "B1 = tf.Variable(tf.random_normal(shape=[1024], stddev=0.01))\n",
    "L1 = tf.nn.sigmoid(tf.matmul(X,W1) + B1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1024, 512], stddev=0.01))\n",
    "B2 = tf.Variable(tf.random_normal(shape=[512], stddev=0.01))\n",
    "L2 = tf.nn.sigmoid(tf.matmul(L1, W2) + B2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512,256], stddev=0.01))\n",
    "B3 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L3 = tf.nn.sigmoid(tf.matmul(L2, W3) + B3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256,10], stddev=0.01))\n",
    "B4 = tf.Variable(tf.random_normal(shape=[10], stddev=0.01))\n",
    "model = tf.nn.softmax(tf.matmul(L3,W4) + B4)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(tf.clip_by_value(model, 1e-10, 1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Avg. cost = 0.899, Train Acc. = 0.6744727277349342\n",
      "Epoch: 0002, Avg. cost = 0.203, Train Acc. = 0.9405272730914029\n",
      "Epoch: 0003, Avg. cost = 0.131, Train Acc. = 0.9612545497850938\n",
      "Epoch: 0004, Avg. cost = 0.099, Train Acc. = 0.9708545537428422\n",
      "Epoch: 0005, Avg. cost = 0.078, Train Acc. = 0.9770727372169494\n",
      "Epoch: 0006, Avg. cost = 0.060, Train Acc. = 0.9822000115567988\n",
      "Epoch: 0007, Avg. cost = 0.050, Train Acc. = 0.9850000104037198\n",
      "Epoch: 0008, Avg. cost = 0.041, Train Acc. = 0.9873818278312683\n",
      "Epoch: 0009, Avg. cost = 0.031, Train Acc. = 0.9903818261623383\n",
      "Epoch: 0010, Avg. cost = 0.028, Train Acc. = 0.9913272804563695\n",
      "Epoch: 0011, Avg. cost = 0.021, Train Acc. = 0.9938363694060932\n",
      "Epoch: 0012, Avg. cost = 0.017, Train Acc. = 0.994654550335624\n",
      "Epoch: 0013, Avg. cost = 0.016, Train Acc. = 0.994963641166687\n",
      "Epoch: 0014, Avg. cost = 0.017, Train Acc. = 0.9948363680189306\n",
      "Epoch: 0015, Avg. cost = 0.013, Train Acc. = 0.996054549108852\n",
      "Training Done!\n",
      "Test Acc. =  0.9787\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        total_acc = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val, acc_val = sess.run([optimizer, cost, accuracy],\n",
    "                                           feed_dict={X:batch_xs, Y:batch_ys})\n",
    "            total_cost += cost_val\n",
    "            total_acc += acc_val\n",
    "            \n",
    "        print('Epoch: {0:04d}, Avg. cost = {1:.3f}, Train Acc. = {2}'.format(epoch + 1,\n",
    "                                                                             total_cost / total_batch,\n",
    "                                                                             total_acc / total_batch))\n",
    "    print('Training Done!')\n",
    "    print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------------------------\n",
    "# ten layers (extream case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784,1024], stddev=0.01))\n",
    "B1 = tf.Variable(tf.random_normal(shape=[1024], stddev=0.01))\n",
    "L1 = tf.nn.sigmoid(tf.matmul(X,W1) + B1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1024, 512], stddev=0.01))\n",
    "B2 = tf.Variable(tf.random_normal(shape=[512], stddev=0.01))\n",
    "L2 = tf.nn.sigmoid(tf.matmul(L1, W2) + B2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512,256], stddev=0.01))\n",
    "B3 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L3 = tf.nn.sigmoid(tf.matmul(L2, W3) + B3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "B4 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L4 = tf.nn.sigmoid(tf.matmul(L3, W4) + B4)\n",
    "\n",
    "W5 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "B5 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L5 = tf.nn.sigmoid(tf.matmul(L4, W5) + B5)\n",
    "\n",
    "W6 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "B6 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L6 = tf.nn.sigmoid(tf.matmul(L5, W6) + B6)\n",
    "\n",
    "W7 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "B7 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L7 = tf.nn.sigmoid(tf.matmul(L6, W7) + B7)\n",
    "\n",
    "W8 = tf.Variable(tf.random_normal([256,256], stddev=0.01))\n",
    "B8 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L8 = tf.nn.sigmoid(tf.matmul(L7, W8) + B8)\n",
    "\n",
    "W9 = tf.Variable(tf.random_normal([256,10], stddev=0.01))\n",
    "B9 = tf.Variable(tf.random_normal(shape=[10], stddev=0.01))\n",
    "model = tf.nn.softmax(tf.matmul(L8,W9) + B9)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(tf.clip_by_value(model, 1e-10, 1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Avg. cost = 2.302, Train Acc. = 0.11212727250361984\n",
      "Epoch: 0002, Avg. cost = 2.233, Train Acc. = 0.12879999996924943\n",
      "Epoch: 0003, Avg. cost = 1.983, Train Acc. = 0.20021818181330509\n",
      "Epoch: 0004, Avg. cost = 1.940, Train Acc. = 0.20167272700504824\n",
      "Epoch: 0005, Avg. cost = 1.888, Train Acc. = 0.2234909088774161\n",
      "Epoch: 0006, Avg. cost = 1.421, Train Acc. = 0.41690908832983536\n",
      "Epoch: 0007, Avg. cost = 1.065, Train Acc. = 0.5457090880654075\n",
      "Epoch: 0008, Avg. cost = 0.779, Train Acc. = 0.6623272740299051\n",
      "Epoch: 0009, Avg. cost = 0.661, Train Acc. = 0.7091454556855289\n",
      "Epoch: 0010, Avg. cost = 0.544, Train Acc. = 0.7818727257034995\n",
      "Epoch: 0011, Avg. cost = 0.431, Train Acc. = 0.8429272711277008\n",
      "Epoch: 0012, Avg. cost = 0.389, Train Acc. = 0.8533818166906183\n",
      "Epoch: 0013, Avg. cost = 0.346, Train Acc. = 0.8620545457709919\n",
      "Epoch: 0014, Avg. cost = 0.335, Train Acc. = 0.865381817817688\n",
      "Epoch: 0015, Avg. cost = 0.324, Train Acc. = 0.867999999631535\n",
      "Training Done!\n",
      "Test Acc. =  0.8605\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        total_acc = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val, acc_val = sess.run([optimizer, cost, accuracy],\n",
    "                                           feed_dict={X:batch_xs, Y:batch_ys})\n",
    "            total_cost += cost_val\n",
    "            total_acc += acc_val\n",
    "            \n",
    "        print('Epoch: {0:04d}, Avg. cost = {1:.3f}, Train Acc. = {2}'.format(epoch + 1,\n",
    "                                                                             total_cost / total_batch,\n",
    "                                                                             total_acc / total_batch))\n",
    "    print('Training Done!')\n",
    "    print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------\n",
    "# apply reLU at 5layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784,1024], stddev=0.01))\n",
    "B1 = tf.Variable(tf.random_normal(shape=[1024], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1) + B1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1024, 512], stddev=0.01))\n",
    "B2 = tf.Variable(tf.random_normal(shape=[512], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + B2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512,256], stddev=0.01))\n",
    "B3 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + B3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256,10], stddev=0.01))\n",
    "B4 = tf.Variable(tf.random_normal(shape=[10], stddev=0.01))\n",
    "model = tf.nn.softmax(tf.matmul(L3,W4) + B4)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(tf.clip_by_value(model, 1e-10, 1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Avg. cost = 0.354, Train Acc. = 0.8852727293968201\n",
      "Epoch: 0002, Avg. cost = 0.116, Train Acc. = 0.9642727318677036\n",
      "Epoch: 0003, Avg. cost = 0.078, Train Acc. = 0.9762181905182925\n",
      "Epoch: 0004, Avg. cost = 0.056, Train Acc. = 0.982963646216826\n",
      "Epoch: 0005, Avg. cost = 0.041, Train Acc. = 0.9869091002507643\n",
      "Epoch: 0006, Avg. cost = 0.034, Train Acc. = 0.9892727355523543\n",
      "Epoch: 0007, Avg. cost = 0.032, Train Acc. = 0.9897636447169564\n",
      "Epoch: 0008, Avg. cost = 0.024, Train Acc. = 0.9921636430783706\n",
      "Epoch: 0009, Avg. cost = 0.022, Train Acc. = 0.993200006051497\n",
      "Epoch: 0010, Avg. cost = 0.022, Train Acc. = 0.9928000065413388\n",
      "Epoch: 0011, Avg. cost = 0.015, Train Acc. = 0.9951272773742675\n",
      "Epoch: 0012, Avg. cost = 0.017, Train Acc. = 0.9950181864608418\n",
      "Epoch: 0013, Avg. cost = 0.014, Train Acc. = 0.995600004196167\n",
      "Epoch: 0014, Avg. cost = 0.013, Train Acc. = 0.9960727309096943\n",
      "Epoch: 0015, Avg. cost = 0.009, Train Acc. = 0.9973090934753418\n",
      "Training Done!\n",
      "Test Acc. =  0.9795\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        total_acc = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val, acc_val = sess.run([optimizer, cost, accuracy],\n",
    "                                           feed_dict={X:batch_xs, Y:batch_ys})\n",
    "            total_cost += cost_val\n",
    "            total_acc += acc_val\n",
    "            \n",
    "        print('Epoch: {0:04d}, Avg. cost = {1:.3f}, Train Acc. = {2}'.format(epoch + 1,\n",
    "                                                                             total_cost / total_batch,\n",
    "                                                                             total_acc / total_batch))\n",
    "    print('Training Done!')\n",
    "    print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------\n",
    "#apply dropout at 5layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784,1024], stddev=0.01))\n",
    "B1 = tf.Variable(tf.random_normal(shape=[1024], stddev=0.01))\n",
    "L1 = tf.nn.relu(tf.matmul(X,W1) + B1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1024, 512], stddev=0.01))\n",
    "B2 = tf.Variable(tf.random_normal(shape=[512], stddev=0.01))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + B2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512,256], stddev=0.01))\n",
    "B3 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + B3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256,10], stddev=0.01))\n",
    "B4 = tf.Variable(tf.random_normal(shape=[10], stddev=0.01))\n",
    "model = tf.nn.softmax(tf.matmul(L3,W4) + B4)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(tf.clip_by_value(model, 1e-10, 1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Avg. cost = 0.397, Train Acc. = 0.8740909094024788\n",
      "Epoch: 0002, Avg. cost = 0.142, Train Acc. = 0.9575636390122501\n",
      "Epoch: 0003, Avg. cost = 0.107, Train Acc. = 0.9685818259282546\n",
      "Epoch: 0004, Avg. cost = 0.083, Train Acc. = 0.9748909187316894\n",
      "Epoch: 0005, Avg. cost = 0.071, Train Acc. = 0.9780363730950788\n",
      "Epoch: 0006, Avg. cost = 0.065, Train Acc. = 0.9801454650272022\n",
      "Epoch: 0007, Avg. cost = 0.055, Train Acc. = 0.9831818282604218\n",
      "Epoch: 0008, Avg. cost = 0.050, Train Acc. = 0.98452728303996\n",
      "Epoch: 0009, Avg. cost = 0.043, Train Acc. = 0.9866545552557165\n",
      "Epoch: 0010, Avg. cost = 0.041, Train Acc. = 0.9873818278312683\n",
      "Epoch: 0011, Avg. cost = 0.039, Train Acc. = 0.9875818272070451\n",
      "Epoch: 0012, Avg. cost = 0.038, Train Acc. = 0.9881818265264685\n",
      "Epoch: 0013, Avg. cost = 0.033, Train Acc. = 0.9900909178907221\n",
      "Epoch: 0014, Avg. cost = 0.033, Train Acc. = 0.9897272811152719\n",
      "Epoch: 0015, Avg. cost = 0.029, Train Acc. = 0.9915818258849057\n",
      "Training Done!\n",
      "Test Acc. =  0.9823\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        total_acc = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val, acc_val = sess.run([optimizer, cost, accuracy],\n",
    "                                           feed_dict={X:batch_xs, Y:batch_ys, keep_prob:0.7})\n",
    "            total_cost += cost_val\n",
    "            total_acc += acc_val\n",
    "            \n",
    "        print('Epoch: {0:04d}, Avg. cost = {1:.3f}, Train Acc. = {2}'.format(epoch + 1,\n",
    "                                                                             total_cost / total_batch,\n",
    "                                                                             total_acc / total_batch))\n",
    "    print('Training Done!')\n",
    "    print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------\n",
    "#apply batch normalization at 5layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-3\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784,1024], stddev=0.01))\n",
    "B1 = tf.Variable(tf.random_normal(shape=[1024], stddev=0.01))\n",
    "L1_BN = tf.matmul(X,W1) + B1\n",
    "batch_mean1, batch_var1 = tf.nn.moments(L1_BN, [0])\n",
    "L1_hat = (L1_BN - batch_mean1)/tf.sqrt(batch_var1+epsilon)\n",
    "scale1 = tf.Variable(tf.ones([1024]))\n",
    "beta1 = tf.Variable(tf.ones([1024]))\n",
    "L1 = tf.nn.relu(scale1*L1_hat + beta1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1024, 512], stddev=0.01))\n",
    "B2 = tf.Variable(tf.random_normal(shape=[512], stddev=0.01))\n",
    "L2_BN = tf.matmul(L1,W2) + B2\n",
    "batch_mean2, batch_var2 = tf.nn.moments(L2_BN, [0])\n",
    "L2_hat = (L2_BN - batch_mean2)/tf.sqrt(batch_var2+epsilon)\n",
    "scale2 = tf.Variable(tf.ones([512]))\n",
    "beta2 = tf.Variable(tf.ones([512]))\n",
    "L2 = tf.nn.relu(scale2*L2_hat + beta2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512,256], stddev=0.01))\n",
    "B3 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L3_BN = tf.matmul(L2,W3) + B3\n",
    "batch_mean3, batch_var3 = tf.nn.moments(L3_BN, [0])\n",
    "L3_hat = (L3_BN - batch_mean3)/tf.sqrt(batch_var3+epsilon)\n",
    "scale3 = tf.Variable(tf.ones([256]))\n",
    "beta3 = tf.Variable(tf.ones([256]))\n",
    "L3 = tf.nn.relu(scale3*L3_hat + beta3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256,10], stddev=0.01))\n",
    "B4 = tf.Variable(tf.random_normal(shape=[10], stddev=0.01))\n",
    "L4_BN = tf.matmul(L3,W4) + B4\n",
    "batch_mean4, batch_var4 = tf.nn.moments(L4_BN, [0])\n",
    "L4_hat = (L4_BN - batch_mean4)/tf.sqrt(batch_var4+epsilon)\n",
    "scale4 = tf.Variable(tf.ones([10]))\n",
    "beta4 = tf.Variable(tf.ones([10]))\n",
    "model = tf.nn.softmax(scale4*L4_hat + beta4)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(tf.clip_by_value(model, 1e-10, 1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Avg. cost = 0.438, Train Acc. = 0.9311454553224824\n",
      "Epoch: 0002, Avg. cost = 0.209, Train Acc. = 0.9634000053189018\n",
      "Epoch: 0003, Avg. cost = 0.141, Train Acc. = 0.9726000081409107\n",
      "Epoch: 0004, Avg. cost = 0.102, Train Acc. = 0.9781091012737968\n",
      "Epoch: 0005, Avg. cost = 0.082, Train Acc. = 0.9811818285421892\n",
      "Epoch: 0006, Avg. cost = 0.066, Train Acc. = 0.9845454649491744\n",
      "Epoch: 0007, Avg. cost = 0.056, Train Acc. = 0.9862363725358789\n",
      "Epoch: 0008, Avg. cost = 0.045, Train Acc. = 0.9894363727352836\n",
      "Epoch: 0009, Avg. cost = 0.041, Train Acc. = 0.9890909176523035\n",
      "Epoch: 0010, Avg. cost = 0.036, Train Acc. = 0.9909090987118808\n",
      "Epoch: 0011, Avg. cost = 0.032, Train Acc. = 0.9916181887279857\n",
      "Epoch: 0012, Avg. cost = 0.027, Train Acc. = 0.99249091592702\n",
      "Epoch: 0013, Avg. cost = 0.026, Train Acc. = 0.9927818247404966\n",
      "Epoch: 0014, Avg. cost = 0.022, Train Acc. = 0.9938727327910336\n",
      "Epoch: 0015, Avg. cost = 0.022, Train Acc. = 0.9938727323575454\n",
      "Training Done!\n",
      "Test Acc. =  0.9814\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        total_acc = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val, acc_val = sess.run([optimizer, cost, accuracy],\n",
    "                                           feed_dict={X:batch_xs, Y:batch_ys, keep_prob:0.7})\n",
    "            total_cost += cost_val\n",
    "            total_acc += acc_val\n",
    "            \n",
    "        print('Epoch: {0:04d}, Avg. cost = {1:.3f}, Train Acc. = {2}'.format(epoch + 1,\n",
    "                                                                             total_cost / total_batch,\n",
    "                                                                             total_acc / total_batch))\n",
    "    print('Training Done!')\n",
    "    print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------\n",
    "####apply dropout + batch normalization at 5layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784,1024], stddev=0.01))\n",
    "B1 = tf.Variable(tf.random_normal(shape=[1024], stddev=0.01))\n",
    "L1_BN = tf.matmul(X,W1) + B1\n",
    "batch_mean1, batch_var1 = tf.nn.moments(L1_BN, [0])\n",
    "L1_hat = (L1_BN - batch_mean1)/tf.sqrt(batch_var1+epsilon)\n",
    "scale1 = tf.Variable(tf.ones([1024]))\n",
    "beta1 = tf.Variable(tf.ones([1024]))\n",
    "L1 = tf.nn.sigmoid(scale1*L1_hat + beta1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1024, 512], stddev=0.01))\n",
    "B2 = tf.Variable(tf.random_normal(shape=[512], stddev=0.01))\n",
    "L2 = tf.nn.sigmoid(tf.matmul(L1, W2) + B2)\n",
    "L2_BN = tf.matmul(L1,W2) + B2\n",
    "batch_mean2, batch_var2 = tf.nn.moments(L2_BN, [0])\n",
    "L2_hat = (L2_BN - batch_mean2)/tf.sqrt(batch_var2+epsilon)\n",
    "scale2 = tf.Variable(tf.ones([512]))\n",
    "beta2 = tf.Variable(tf.ones([512]))\n",
    "L2 = tf.nn.sigmoid(scale2*L2_hat + beta2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512,256], stddev=0.01))\n",
    "B3 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L3_BN = tf.matmul(L2,W3) + B3\n",
    "batch_mean3, batch_var3 = tf.nn.moments(L3_BN, [0])\n",
    "L3_hat = (L3_BN - batch_mean3)/tf.sqrt(batch_var3+epsilon)\n",
    "scale3 = tf.Variable(tf.ones([256]))\n",
    "beta3 = tf.Variable(tf.ones([256]))\n",
    "L3 = tf.nn.sigmoid(scale3*L3_hat + beta3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256,10], stddev=0.01))\n",
    "B4 = tf.Variable(tf.random_normal(shape=[10], stddev=0.01))\n",
    "L4_BN = tf.matmul(L3,W4) + B4\n",
    "batch_mean4, batch_var4 = tf.nn.moments(L4_BN, [0])\n",
    "L4_hat = (L4_BN - batch_mean4)/tf.sqrt(batch_var4+epsilon)\n",
    "scale4 = tf.Variable(tf.ones([10]))\n",
    "beta4 = tf.Variable(tf.ones([10]))\n",
    "model = tf.nn.softmax(scale4*L4_hat + beta4)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(tf.clip_by_value(model, 1e-10, 1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Avg. cost = 0.769, Train Acc. = 0.8313636355102062\n",
      "Epoch: 0002, Avg. cost = 0.467, Train Acc. = 0.8932909114794297\n",
      "Epoch: 0003, Avg. cost = 0.346, Train Acc. = 0.9154000020027161\n",
      "Epoch: 0004, Avg. cost = 0.291, Train Acc. = 0.9237272757833654\n",
      "Epoch: 0005, Avg. cost = 0.247, Train Acc. = 0.9353818199851296\n",
      "Epoch: 0006, Avg. cost = 0.225, Train Acc. = 0.9376181833310561\n",
      "Epoch: 0007, Avg. cost = 0.200, Train Acc. = 0.9442363650148565\n",
      "Epoch: 0008, Avg. cost = 0.177, Train Acc. = 0.9504909119822762\n",
      "Epoch: 0009, Avg. cost = 0.169, Train Acc. = 0.9515636385570873\n",
      "Epoch: 0010, Avg. cost = 0.156, Train Acc. = 0.9556363666057587\n",
      "Epoch: 0011, Avg. cost = 0.147, Train Acc. = 0.9580000022324648\n",
      "Epoch: 0012, Avg. cost = 0.139, Train Acc. = 0.9591454582864588\n",
      "Epoch: 0013, Avg. cost = 0.130, Train Acc. = 0.9619272767413746\n",
      "Epoch: 0014, Avg. cost = 0.119, Train Acc. = 0.9649090976064856\n",
      "Epoch: 0015, Avg. cost = 0.118, Train Acc. = 0.9650181883031672\n",
      "Training Done!\n",
      "Test Acc. =  0.9787\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        total_acc = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val, acc_val = sess.run([optimizer, cost, accuracy],\n",
    "                                           feed_dict={X:batch_xs, Y:batch_ys, keep_prob:0.7})\n",
    "            total_cost += cost_val\n",
    "            total_acc += acc_val\n",
    "            \n",
    "        print('Epoch: {0:04d}, Avg. cost = {1:.3f}, Train Acc. = {2}'.format(epoch + 1,\n",
    "                                                                             total_cost / total_batch,\n",
    "                                                                             total_acc / total_batch))\n",
    "    print('Training Done!')\n",
    "    print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------\n",
    "#apply dropout + batch normalization + ReLU at 5layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784,1024], stddev=0.01))\n",
    "B1 = tf.Variable(tf.random_normal(shape=[1024], stddev=0.01))\n",
    "L1_BN = tf.matmul(X,W1) + B1\n",
    "batch_mean1, batch_var1 = tf.nn.moments(L1_BN, [0])\n",
    "L1_hat = (L1_BN - batch_mean1)/tf.sqrt(batch_var1+epsilon)\n",
    "scale1 = tf.Variable(tf.ones([1024]))\n",
    "beta1 = tf.Variable(tf.ones([1024]))\n",
    "L1 = tf.nn.relu(scale1*L1_hat + beta1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1024, 512], stddev=0.01))\n",
    "B2 = tf.Variable(tf.random_normal(shape=[512], stddev=0.01))\n",
    "L2 = tf.nn.sigmoid(tf.matmul(L1, W2) + B2)\n",
    "L2_BN = tf.matmul(L1,W2) + B2\n",
    "batch_mean2, batch_var2 = tf.nn.moments(L2_BN, [0])\n",
    "L2_hat = (L2_BN - batch_mean2)/tf.sqrt(batch_var2+epsilon)\n",
    "scale2 = tf.Variable(tf.ones([512]))\n",
    "beta2 = tf.Variable(tf.ones([512]))\n",
    "L2 = tf.nn.relu(scale2*L2_hat + beta2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512,256], stddev=0.01))\n",
    "B3 = tf.Variable(tf.random_normal(shape=[256], stddev=0.01))\n",
    "L3_BN = tf.matmul(L2,W3) + B3\n",
    "batch_mean3, batch_var3 = tf.nn.moments(L3_BN, [0])\n",
    "L3_hat = (L3_BN - batch_mean3)/tf.sqrt(batch_var3+epsilon)\n",
    "scale3 = tf.Variable(tf.ones([256]))\n",
    "beta3 = tf.Variable(tf.ones([256]))\n",
    "L3 = tf.nn.relu(scale3*L3_hat + beta3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([256,10], stddev=0.01))\n",
    "B4 = tf.Variable(tf.random_normal(shape=[10], stddev=0.01))\n",
    "L4_BN = tf.matmul(L3,W4) + B4\n",
    "batch_mean4, batch_var4 = tf.nn.moments(L4_BN, [0])\n",
    "L4_hat = (L4_BN - batch_mean4)/tf.sqrt(batch_var4+epsilon)\n",
    "scale4 = tf.Variable(tf.ones([10]))\n",
    "beta4 = tf.Variable(tf.ones([10]))\n",
    "model = tf.nn.softmax(scale4*L4_hat + beta4)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(tf.clip_by_value(model, 1e-10, 1.0)), [1]))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, Avg. cost = 0.571, Train Acc. = 0.8936000008610162\n",
      "Epoch: 0002, Avg. cost = 0.294, Train Acc. = 0.9418909095634114\n",
      "Epoch: 0003, Avg. cost = 0.207, Train Acc. = 0.9548545479774475\n",
      "Epoch: 0004, Avg. cost = 0.157, Train Acc. = 0.9637454591014168\n",
      "Epoch: 0005, Avg. cost = 0.131, Train Acc. = 0.9684545537558469\n",
      "Epoch: 0006, Avg. cost = 0.111, Train Acc. = 0.9721272820776159\n",
      "Epoch: 0007, Avg. cost = 0.096, Train Acc. = 0.9742363720590418\n",
      "Epoch: 0008, Avg. cost = 0.087, Train Acc. = 0.9771636466546492\n",
      "Epoch: 0009, Avg. cost = 0.075, Train Acc. = 0.9799272829836065\n",
      "Epoch: 0010, Avg. cost = 0.068, Train Acc. = 0.9810909200798381\n",
      "Epoch: 0011, Avg. cost = 0.061, Train Acc. = 0.9830000112273476\n",
      "Epoch: 0012, Avg. cost = 0.060, Train Acc. = 0.9827272831309926\n",
      "Epoch: 0013, Avg. cost = 0.050, Train Acc. = 0.9864363740790975\n",
      "Epoch: 0014, Avg. cost = 0.052, Train Acc. = 0.9852545560490001\n",
      "Epoch: 0015, Avg. cost = 0.044, Train Acc. = 0.9876363730430603\n",
      "Training Done!\n",
      "Test Acc. =  0.9838\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        total_cost = 0\n",
    "        total_acc = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, cost_val, acc_val = sess.run([optimizer, cost, accuracy],\n",
    "                                           feed_dict={X:batch_xs, Y:batch_ys, keep_prob:0.7})\n",
    "            total_cost += cost_val\n",
    "            total_acc += acc_val\n",
    "            \n",
    "        print('Epoch: {0:04d}, Avg. cost = {1:.3f}, Train Acc. = {2}'.format(epoch + 1,\n",
    "                                                                             total_cost / total_batch,\n",
    "                                                                             total_acc / total_batch))\n",
    "    print('Training Done!')\n",
    "    print('Test Acc. = ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
